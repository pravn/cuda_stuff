Experiments in CUDA.
Sources: Wen-Mei Hwu's book, Shane Cook's book and parallelforall blog.

1) matmul_naive: Trivial matrix multiplication with no attempt at parallelization.
2) matmul_shem: Tiling and shared memory (incomplete).
3) ballot - attempt at using ballot+popc to replace atomics. Single block.
	- ballot_atomicadd1 uses an atomicOr to collect ballot return.
	- ballot_atomicadd2 stores results of ballot in register and reduces 
4) shffl - shffl instructions to do reductions. 

5) histogram - using ballot and atomics to compute histogram. ballot
	implementation simply adds an extra array dimension to 3) for each
	bin. Check later to compare speed with that of atomicAdd.

6) thrust - pulled out stream compaction sample from thrust repo. Ignorable.

TODO
	Multiblock kernels for ballot, shuffl, histogram and atomics.
	Atomics in shared memory and private per thread histograms from
	Nicholas Wilt's article online.
	Timing experiments for various tests. In particular

	Atomics performance where threads write to a small number of bins.
	The hope is make an evaluation of various methods and pronounce which
	one of them is the most performant.

	a) Naive and Shared memory atomics
	b) Per thread histogram as per Wilt
	c) Ballot+Popc followed by a subsequent reduction.
	