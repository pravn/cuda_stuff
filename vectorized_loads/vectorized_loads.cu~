#include <iostream>
#include <Timer.h>

//I am planning to use this to improve performance in atomics kernels

//from Justin Luitjens' blog post in parallelforall (CUDA Pro Tip: Increase performance with vectorized loads)
//https://devblogs.nvidia.com/parallelforall/cuda-pro-tip-increase-performance-with-vectorized-memory-access/
__global__ void device_copy_vec4_kernel(int *d_in, int *d_out, int N){

  int idx = blockIdx.x*blockDim.x + threadIdx.x;
  for(int i=idx; i<N/4; i+ = blockDim.x*gridDim.x)
    reinterpret_cast<int4*> (d_out)[i] = reinterpret_cast<int4*>(d_in)[i];
  
